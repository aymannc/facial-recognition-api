{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of web_service",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1nb3hExsdw-0MH7NBpu7RHkUeI8odRSJ7",
      "authorship_tag": "ABX9TyPVHcqogii1+RGwJTIOLM+Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aymannc/facial-recognition-api/blob/master/web_service.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-ugr2fBnNTh",
        "colab_type": "code",
        "outputId": "01a9fab7-7116-4062-cd6d-3ef1d05cc2c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "!pip install flask-ngrok\n",
        "!pip install face_recognition\n",
        "!pip install pathlib\n",
        "!pip install Pillow\n",
        "!pip install opencv-python\n",
        "!pip  install flask-cors"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.6/dist-packages (0.0.25)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.6/dist-packages (from flask-ngrok) (1.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.2)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=0.8->flask-ngrok) (1.1.1)\n",
            "Requirement already satisfied: face_recognition in /usr/local/lib/python3.6/dist-packages (1.3.0)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (19.18.0)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from face_recognition) (1.18.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from face_recognition) (7.0.0)\n",
            "Requirement already satisfied: face-recognition-models>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (0.3.0)\n",
            "Requirement already satisfied: pathlib in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (7.0.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.18.4)\n",
            "Requirement already satisfied: flask-cors in /usr/local/lib/python3.6/dist-packages (3.0.8)\n",
            "Requirement already satisfied: Six in /usr/local/lib/python3.6/dist-packages (from flask-cors) (1.12.0)\n",
            "Requirement already satisfied: Flask>=0.9 in /usr/local/lib/python3.6/dist-packages (from flask-cors) (1.1.2)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.9->flask-cors) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.9->flask-cors) (1.0.1)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.9->flask-cors) (2.11.2)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.9->flask-cors) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=0.9->flask-cors) (1.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BWPmwPZra4J",
        "colab_type": "code",
        "outputId": "5c660309-335d-41cc-bb97-45761cca4ca9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import dlib.cuda as cuda\n",
        "print(cuda.get_num_devices())\n",
        "import gc\n",
        "import os\n",
        "import pickle\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "import cv2\n",
        "import face_recognition\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from flask import Flask, jsonify, request, send_from_directory, Response\n",
        "from flask_cors import CORS\n",
        "from imutils import paths\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask\n",
        "\n",
        "from IPython.display import Image as show_image\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDz2ZkcBxfZS",
        "colab_type": "code",
        "outputId": "8e45f8f3-73d1-4829-f3e4-ae69c9424368",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!ls \"/content/drive/My Drive/FaceRec Project/dataset\"\n",
        "!ls \"/content/drive/My Drive/FaceRec Project/results\""
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Achir\t      Assimi\t   Bourase   Ghomari\t   Khattach    Redouani\n",
            " Ahriz\t      Atibi\t   Chafi     Habil\t   Lablaoui    Sabar\n",
            "'Ait Alla'   'Ayman NC'    Chihab    Haddadi\t   Meslouhi    Sakhi\n",
            "'Ait Daoud'   BabaKhouya   Chihi    'Haj Sallem'   Ouftou      Youssfi\n",
            " Amzil\t      Badaoui\t   Dadi      Hamman\t   Oulahyane   Zedouti\n",
            " Annan\t      Benmousa\t   Faiq      KhaifAllah    Ounjim\n",
            " Anssari      Berrada\t   Geuddi    Kharazi\t   rat\n",
            "1591216617.2455087.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gf-I8texr5n4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'gif'}\n",
        "data_set_path=\"/content/drive/My Drive/FaceRec Project/dataset\"\n",
        "results_path=\"/content/drive/My Drive/FaceRec Project/results\"\n",
        "encodings_path=\"/content/drive/My Drive/FaceRec Project/encodings.pickle\"\n",
        "\n",
        "app = Flask(__name__, static_url_path='')\n",
        "CORS(app)\n",
        "\n",
        "run_with_ngrok(app)\n",
        "data = {}\n",
        "data_load_time = 0.0\n",
        "number_of_requests = 0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MFvg7AzscPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@app.route('/uploads/<path:path>')\n",
        "def download_file(path):\n",
        "    #return send_from_directory(app.config['UPLOAD_FOLDER'], path)\n",
        "    return Response(\"Not defined!\", status=404)\n",
        "\n",
        "\n",
        "@app.route('/results/<path:path>')\n",
        "def download_results_image(path):\n",
        "    #return send_from_directory(app.config['RESULTS_FOLDER'], path)\n",
        "    return Response(\"Not defined!\", status=404)\n",
        "\n",
        "\n",
        "def load_global_data():\n",
        "    global data\n",
        "    global data_load_time\n",
        "    start_time = time.time()\n",
        "    print(\"[INFO] loading data\")\n",
        "    data = pickle.loads(open(encodings_path, \"rb\").read())\n",
        "    data_load_time = time.time() - start_time\n",
        "    print(f\"[INFO] Done loading data\")\n",
        "\n",
        "\n",
        "def allowed_file(filename):\n",
        "    return '.' in filename and \\\n",
        "           filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nYi_qPUpRf9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "@app.route('/upload_images', methods=['POST'])\n",
        "def upload_file():\n",
        "    username = request.form.get('username') or \"default\"\n",
        "    if request.method == 'POST' and 'files' in request.files:\n",
        "        link_list = []\n",
        "        try:\n",
        "            for file in request.files.getlist('files'):\n",
        "                if file and allowed_file(file.filename):\n",
        "                    base_path = os.path.join(data_set_path, username)\n",
        "                    file_name = f\"{username}_{time.time()}{file.filename}\"\n",
        "                    Path(base_path).mkdir(parents=True, exist_ok=True)\n",
        "                    full_path = os.path.join(base_path, file_name)\n",
        "                    file.save(full_path)\n",
        "                    link_list.append(f\"{upload_url}{username}/{file_name}\")\n",
        "        except Exception as _:\n",
        "            pass\n",
        "        return jsonify({\"file_path\": link_list})\n",
        "\n",
        "@app.route('/facial_recognition', methods=['GET', 'POST'])\n",
        "def upload_image():\n",
        "    # Check if a valid image file was uploaded\n",
        "    if request.method == 'POST':\n",
        "        if 'file' not in request.files:\n",
        "            return Response(\n",
        "                \"No image uploaded!\",\n",
        "                status=404\n",
        "            )\n",
        "\n",
        "        file = request.files['file']\n",
        "\n",
        "        if file.filename == '':\n",
        "            return Response(\"Image error!\", status=415)\n",
        "\n",
        "        if file and allowed_file(file.filename):\n",
        "            # The image file seems valid! Detect faces and return the result.\n",
        "            return detect_faces_in_image(file)\n",
        "\n",
        "    # If no valid image file was uploaded, show the file upload form:\n",
        "    return '''\n",
        "    <!doctype html>\n",
        "    <title>Is this a picture of X?</title>\n",
        "    <h1>Upload a picture !</h1>\n",
        "    <form method=\"POST\" enctype=\"multipart/form-data\">\n",
        "      <input type=\"file\" name=\"file\">\n",
        "      <input type=\"submit\" value=\"Upload\">\n",
        "    </form>\n",
        "    '''\n",
        "\n",
        "\n",
        "@app.route('/faces_encoding', methods=['GET', 'POST'])\n",
        "def faces_encoding():\n",
        "    successful = True\n",
        "    error_message = None\n",
        "\n",
        "    start_time = time.time()\n",
        "    try:\n",
        "        print(\"[INFO] quantifying faces...\")\n",
        "        # Example of output ['dataset\\\\anc\\\\Nait Cherif.jpg',...]\n",
        "        imagePaths = list(paths.list_images(data_set_path))\n",
        "        print(imagePaths)\n",
        "        # initialize the list of known encodings and known names\n",
        "        # print(imagePaths)\n",
        "        knownEncodings = []\n",
        "        knownNames = []\n",
        "\n",
        "        for (i, imagePath) in enumerate(imagePaths):\n",
        "            # extract the person name from the image path\n",
        "            print(f\"[INFO] processing image {i + 1}/{len(imagePaths)}\")\n",
        "            name = imagePath.split(os.path.sep)[-2]\n",
        "            # load the input image and convert it from BGR (OpenCV ordering)\n",
        "            # to dlib ordering (RGB)\n",
        "            image = cv2.imread(imagePath)\n",
        "            height, width, _ = image.shape\n",
        "            rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # detect the (x, y)-coordinates of the bounding boxes\n",
        "            # corresponding to each face in the input image\n",
        "            boxes = face_recognition.face_locations(rgb, model=\"cnn\")\n",
        "            # compute the facial embedding for the face\n",
        "            encodings = face_recognition.face_encodings(rgb, boxes)\n",
        "            # loop over the encodings\n",
        "            for encoding in encodings:\n",
        "                # add each encoding + name to our set of known names and\n",
        "                # encodings\n",
        "                knownEncodings.append(encoding)\n",
        "                knownNames.append(name)\n",
        "\n",
        "        # dump the facial encodings + names to disk\n",
        "        print(\"[INFO] serializing encodings...\")\n",
        "        i_data = {\"encodings\": knownEncodings, \"names\": knownNames}\n",
        "        with open(encodings_path, \"wb\") as f:\n",
        "            f.write(pickle.dumps(i_data))\n",
        "    except Exception as e:\n",
        "        successful = False\n",
        "        error_message = e\n",
        "        print(e)\n",
        "    finally:\n",
        "        return jsonify({\n",
        "            \"successful\": successful,\n",
        "            \"error_message\": str(error_message),\n",
        "            \"time_to_complete\": time.time() - start_time\n",
        "        })\n",
        "\n",
        "\n",
        "def detect_faces_in_image(file_stream):\n",
        "    load_global_data()\n",
        "    start_time = time.time()\n",
        "    print(\"[INFO] recognizing faces...\")\n",
        "    # Load the uploaded image file\n",
        "    original_img = Image.open(file_stream).convert('RGB')\n",
        "    img = np.array(original_img)\n",
        "    boxes = face_recognition.face_locations(img, model=\"cnn\")\n",
        "    encodings = face_recognition.face_encodings(img, boxes)\n",
        "    # Get face encodings for any faces in the uploaded image\n",
        "    names = []\n",
        "\n",
        "    for encoding in encodings:\n",
        "        global data\n",
        "        matches = face_recognition.compare_faces(\n",
        "            data[\"encodings\"], encoding, tolerance=0.5)\n",
        "        name = \"Unknown\"\n",
        "        if True in matches:\n",
        "            # find the indexes of all matched faces then initialize a\n",
        "            # dictionary to count the total number of times each face\n",
        "            # was matched\n",
        "            matchedIdxs = [i for (i, b) in enumerate(matches) if b]\n",
        "            counts = {}\n",
        "            # loop over the matched indexes and maintain a count for\n",
        "            # each recognized face\n",
        "            for i in matchedIdxs:\n",
        "                name = data[\"names\"][i]\n",
        "                counts[name] = counts.get(name, 0) + 1\n",
        "            # determine the recognized face with the largest number of\n",
        "            # votes (note: in the event of an unlikely tie Python will\n",
        "            # select first entry in the dictionary)\n",
        "            name = max(counts, key=counts.get)\n",
        "            print(\"[INFO]counts\", counts)\n",
        "            # update the list of names\n",
        "        names.append(name)\n",
        "    image = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "    for (top, right, bottom, left), name in zip(boxes, names):\n",
        "        # Draw a box around the face\n",
        "        cv2.rectangle(image, (left - 20, top - 20),\n",
        "                      (right + 20, bottom + 20), (255, 0, 0), 2)\n",
        "\n",
        "        # Draw a label with a name below the face\n",
        "        cv2.rectangle(image, (left - 20, bottom),\n",
        "                      (right + 20, bottom + 20), (255, 0, 0), cv2.FILLED)\n",
        "        font = cv2.FONT_HERSHEY_DUPLEX\n",
        "        cv2.putText(image, name, (left - 20, bottom + 15),\n",
        "                    font, 0.7, (255, 255, 255))\n",
        "\n",
        "    # show the output image\n",
        "    file_name = f\"{time.time()}.jpg\"\n",
        "    file_path = f\"{results_path}/{file_name}\"\n",
        "    cv2.imwrite(file_path, image)\n",
        "    show_image(file_path)\n",
        "    result = {\n",
        "        \"faces_found_in_image\": names,\n",
        "        \"faces_load_time\": data_load_time,\n",
        "        \"data_rec_time\": time.time() - start_time,\n",
        "        \"results_file_url\": f\"{results_path}{file_name}\"\n",
        "    }\n",
        "    return jsonify(result)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-CvQhiKtfsv",
        "colab_type": "code",
        "outputId": "c49a194a-27b6-4479-d224-5beeb2790c04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # TODO : fix aout of memory clean code\n",
        "    app.run()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://e8f80064ad3a.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukWOF1lxnYYF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}